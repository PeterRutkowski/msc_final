{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annoying-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifteen-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('pipeline_data/x_train_none_none.npz', allow_pickle=True)['data']\n",
    "x_test = np.load('pipeline_data/x_test_none_none.npz', allow_pickle=True)['data']\n",
    "y_train = np.load('pipeline_data/y_train.npz', allow_pickle=True)['data']\n",
    "y_test = np.load('pipeline_data/y_test.npz', allow_pickle=True)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complicated-recall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 1000), (3000, 1000), (10000,), (3000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confirmed-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, D_out = x_train.shape[0], x_train.shape[1], 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = np.squeeze(torch.LongTensor(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "architectural-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_out),\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "    \n",
    "losses = []\n",
    "\n",
    "batchs = 256\n",
    "    \n",
    "trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batchs,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "batchesn = int(N/batchs)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "novel-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, datap in enumerate(trainloader, 0):\n",
    "        inputs, labels = datap\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % batchesn == batchesn-1:\n",
    "            running_loss = 0.0\n",
    "    scheduler.step()\n",
    "  \n",
    "torch.save(model, 'pipeline_data/nn_benchmark.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chubby-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('pipeline_data/nn_benchmark.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adopted-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples correct=2744 accuracy=0.915\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.Tensor(x_test)\n",
    "y_test = np.squeeze(torch.LongTensor(y_test))\n",
    "\n",
    "model.eval()\n",
    "outputs = model(x_test)\n",
    "probals, predicted = torch.max(outputs, 1)\n",
    "\n",
    "c = (predicted == y_test).squeeze()\n",
    "correct = c.sum().item()\n",
    "print('samples correct={} accuracy={}'.format(correct, np.round(correct/x_test.shape[0], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "voluntary-precipitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_data/x_test_salt_pepper_noise_0.03.npz 0.858\n",
      "pipeline_data/x_test_salt_pepper_noise_0.06.npz 0.811\n",
      "pipeline_data/x_test_salt_pepper_noise_0.09.npz 0.771\n",
      "pipeline_data/x_test_salt_pepper_noise_0.12.npz 0.727\n",
      "pipeline_data/x_test_salt_pepper_noise_0.15.npz 0.695\n",
      "pipeline_data/x_test_salt_pepper_noise_0.18.npz 0.647\n",
      "pipeline_data/x_test_salt_pepper_noise_0.21.npz 0.616\n",
      "pipeline_data/x_test_salt_pepper_noise_0.24.npz 0.583\n",
      "pipeline_data/x_test_salt_pepper_noise_0.27.npz 0.536\n",
      "pipeline_data/x_test_salt_pepper_noise_0.30.npz 0.506\n",
      "pipeline_data/x_test_salt_pepper_noise_0.33.npz 0.459\n"
     ]
    }
   ],
   "source": [
    "for set_path in ['pipeline_data/x_test_salt_pepper_noise_0.03.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.06.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.09.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.12.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.15.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.18.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.21.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.24.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.27.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.30.npz',\n",
    "                 'pipeline_data/x_test_salt_pepper_noise_0.33.npz']:\n",
    "    x = torch.Tensor(np.load(set_path, allow_pickle=True)['data'])\n",
    "    y = np.squeeze(torch.LongTensor(\n",
    "        np.load('pipeline_data/y_test.npz', allow_pickle=True)['data']))\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(x)\n",
    "    probals, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    c = (predicted == y).squeeze()\n",
    "    correct = c.sum().item()\n",
    "    print('{} {}'.format(set_path, np.round(correct/x.shape[0], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "married-sperm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples correct=2743 accuracy=0.914\n",
      "samples correct=2722 accuracy=0.907\n",
      "samples correct=2661 accuracy=0.887\n",
      "samples correct=2602 accuracy=0.867\n",
      "samples correct=2527 accuracy=0.842\n",
      "samples correct=2424 accuracy=0.808\n",
      "samples correct=2331 accuracy=0.777\n",
      "samples correct=2219 accuracy=0.74\n",
      "samples correct=2109 accuracy=0.703\n",
      "samples correct=1990 accuracy=0.663\n",
      "samples correct=1891 accuracy=0.63\n"
     ]
    }
   ],
   "source": [
    "for set_path in ['pipeline_data/x_test_gaussian_blur_0.5.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_1.0.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_1.5.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_2.0.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_2.5.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_3.0.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_3.5.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_4.0.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_4.5.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_5.0.npz',\n",
    "                 'pipeline_data/x_test_gaussian_blur_5.5.npz']:\n",
    "    x = torch.Tensor(np.load(set_path, allow_pickle=True)['data'])\n",
    "    y = np.squeeze(torch.LongTensor(\n",
    "        np.load('pipeline_data/y_test.npz', allow_pickle=True)['data']))\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(x)\n",
    "    probals, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    c = (predicted == y).squeeze()\n",
    "    correct = c.sum().item()\n",
    "    print('samples correct={} accuracy={}'.format(correct, np.round(correct/x.shape[0], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "allied-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples correct=2746 accuracy=0.915\n",
      "samples correct=2704 accuracy=0.901\n",
      "samples correct=2641 accuracy=0.88\n",
      "samples correct=2550 accuracy=0.85\n",
      "samples correct=2430 accuracy=0.81\n",
      "samples correct=2303 accuracy=0.768\n",
      "samples correct=2156 accuracy=0.719\n",
      "samples correct=1988 accuracy=0.663\n",
      "samples correct=1847 accuracy=0.616\n",
      "samples correct=1698 accuracy=0.566\n",
      "samples correct=1552 accuracy=0.517\n"
     ]
    }
   ],
   "source": [
    "for set_path in ['pipeline_data/x_test_gaussian_noise_10.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_20.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_30.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_40.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_50.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_60.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_70.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_80.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_90.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_100.npz',\n",
    "                 'pipeline_data/x_test_gaussian_noise_110.npz']:\n",
    "    x = torch.Tensor(np.load(set_path, allow_pickle=True)['data'])\n",
    "    y = np.squeeze(torch.LongTensor(\n",
    "        np.load('pipeline_data/y_test.npz', allow_pickle=True)['data']))\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(x)\n",
    "    probals, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    c = (predicted == y).squeeze()\n",
    "    correct = c.sum().item()\n",
    "    print('samples correct={} accuracy={}'.format(correct, np.round(correct/x.shape[0], 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-black",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
